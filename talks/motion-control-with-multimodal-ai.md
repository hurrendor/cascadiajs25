# Motion Control With Multimodal AI 

## Charlie Gerard
### CrowdStrike, Oakland, CA, USA 
- [Linkedin](https://www.linkedin.com/in/charliegerard/) 

- [X / Twitter](https://x.com/devdevcharlie) 

- [Bluesky](https://bsky.app/profile/devdevcharlie.com) 

- [Github](https://github.com/charliegerard) 

- [Speaker's Notes (Placeholder)]()
- [Post-conference YouTube Recording (Placeholder)]()
## Abstract: 

What if you could use multimodal LLMs to interact with websites or IoT devices using motion control? As advancements in multimodal AI offer new opportunities to push the boundaries of what can be done with this technology, I started wondering how it could be leveraged from the perspective of human-computer interaction. In this talk, I will take you through my research experimenting with building motion-controlled prototypes using LLMs in JavaScript.
## Community talk notes: 